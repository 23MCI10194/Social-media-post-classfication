import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
data = pd.read_csv('1000_students_data.csv')
# Data preprocessing
def preprocess_data(df):
    processed_df = df.copy()

    # Handle missing values
    for column in processed_df.columns:
        if processed_df[column].dtype == 'object':
            processed_df[column].fillna(processed_df[column].mode()[0], inplace=True)
        else:
            processed_df[column].fillna(processed_df[column].median(), inplace=True)

    # Encode categorical variables
    label_encoders = {}
    categorical_columns = processed_df.select_dtypes(include=['object']).columns

    for column in categorical_columns:
        label_encoders[column] = LabelEncoder()
        processed_df[column] = label_encoders[column].fit_transform(processed_df[column])

    return processed_df, label_encoders

# Preprocess the data
processed_data, label_encoders = preprocess_data(data)

# Create visualizations for original data distribution
# Platform distribution
platform_counts = data['Which Social Media Platform do you use the Most?'].value_counts()
platform_labels = platform_counts.index

# Age distribution
age_counts = data['Age'].value_counts().sort_index()
age_labels = age_counts.index

# Category distribution
category_counts = data['Category of the Post'].value_counts()
category_labels = category_counts.index

# Create visualizations
plt.figure(figsize=(15, 10))

# Platform distribution
plt.subplot(2, 1, 1)
plt.bar(platform_labels, platform_counts.values, color=['blue', 'orange', 'green', 'red'])
plt.title('Distribution of Social Media Platforms Used by Students')
plt.xlabel('Social Media Platform')
plt.ylabel('Number of Users')
plt.xticks(rotation=45)
plt.grid(axis='y')

# Age distribution
plt.subplot(2, 1, 2)
plt.bar(age_labels, age_counts.values, color='skyblue')
plt.title('Distribution of Student Ages')
plt.xlabel('Age')
plt.ylabel('Number of Students')
plt.grid(axis='y')

plt.tight_layout()
plt.show()

# Category distribution
plt.figure(figsize=(12, 6))
plt.bar(category_labels, category_counts.values, color='lightgreen')
plt.title('Distribution of Social Media Post Categories')
plt.xlabel('Post Category')
plt.ylabel('Number of Posts')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# Pie chart for platform distribution
plt.figure(figsize=(10, 8))
plt.pie(platform_counts.values, labels=platform_labels, autopct='%1.1f%%')
plt.title('Social Media Platform Usage')
plt.axis('equal')
plt.show()

# Prepare features and target for modeling
X = processed_data.drop(['Which Social Media Platform do you use the Most?'], axis=1)
y = processed_data['Which Social Media Platform do you use the Most?']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define base model
rf_model = RandomForestClassifier(n_jobs=-1, random_state=42)

# Define simplified parameter grid
param_dist = {
    'n_estimators': [50, 100],
    'max_depth': [10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

# Perform RandomizedSearchCV
random_search = RandomizedSearchCV(
    rf_model,
    param_distributions=param_dist,
    n_iter=5,
    cv=3,
    n_jobs=-1,
    verbose=1,
    random_state=42
)

# Fit the model
print("Training the model...")
random_search.fit(X_train_scaled, y_train)

# Get best model
best_model = random_search.best_estimator_

# Make predictions
y_pred = best_model.predict(X_test_scaled)

# Print results
print("\nBest parameters:", random_search.best_params_)
print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
target_names = label_encoders['Which Social Media Platform do you use the Most?'].inverse_transform(range(len(label_encoders['Which Social Media Platform do you use the Most?'].classes_)))
print(classification_report(y_test, y_pred, target_names=target_names))

# Feature importance visualization
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': best_model.feature_importances_
}).sort_values('importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=feature_importance)
plt.title('Feature Importance')
plt.tight_layout()
plt.show()

# Confusion matrix visualization
cm = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.tight_layout()
plt.show()

# Print importance of social media post classification
print("\nImportance of Social Media Post Classification:")
print("1. Targeted Content Delivery: Helps platforms deliver relevant content to users.")
print("2. Trend Identification: Identifies popular topics and emerging trends.")
print("3. Sentiment Analysis: Assists in understanding user sentiment towards topics.")
print("4. Audience Segmentation: Enables targeted marketing campaigns.")
print("5. Competitive Analysis: Provides insights into competitors' content strategies.")
print("6. Influencer Identification: Helps identify influential users in specific categories.")
print("7. Moderation and Safety: Aids in content moderation and policy enforcement.")
